import os
import pathlib
import logging
import pandas as pd
import geopandas as gpd
import numpy as np
import seaborn as sns

from abc import abstractmethod

from mobility.file_asset import FileAsset
from mobility import radiation_model_selection
from mobility.choice_models.travel_costs_aggregator import TravelCostsAggregator

class DestinationChoiceModel(FileAsset):
    """
    A generic class for destination choice models, with a subclass for every motive.
    
    Currently implemented :
        - WorkDestinationChoiceModel, for home-work flows.
    """
    
    def __init__(
            self,
            motive: str,
            transport_zones: gpd.GeoDataFrame, 
            modes,
            parameters,
            ssi_min_flow_volume: float
        ):
        """Retrieves destination choice model if it already exists for these transport zones, travel costs, motive and other parameters.
        Otherwise, creates it and saves it.

        Parameters
        ----------
        motive : str
            Currently implemented: "work".
        transport_zones : gpd.GeoDataFrame
            Transport zones generated by TransportZones class.
        travel_costs : TravelCosts
            Travel costs generated by TravelCosts class.
        model_parameters : dict
            Depend on the motive, check the specific class (such as WorkDestinationChoiceModel) for details.
        utility_parameters : dict
            Depend on the motive, check the specific class (such as WorkDestinationChoiceModel) for details.
        ssi_min_flow_volume : float
            Minimum reference volume to consider for similarity index.
        """
        
        costs = TravelCostsAggregator(modes)
        
        inputs = {
            "motive": motive,
            "transport_zones": transport_zones,
            "costs": costs,
            "parameters": parameters,
            "ssi_min_flow_volume": ssi_min_flow_volume
        }
        
        data_folder = pathlib.Path(os.environ["MOBILITY_PROJECT_DATA_FOLDER"])
        od_flows_filename = motive + "_od_flows.parquet"
        dest_cm_filename = motive + "_destination_choice_model.parquet"
        utility_by_od_and_mode_filename = motive + "_utility_by_od_and_mode.parquet"
        
        cache_path = {
            "od_flows": data_folder / od_flows_filename,
            "destination_choice_model": data_folder / dest_cm_filename,
            "utility_by_od_and_mode": data_folder / utility_by_od_and_mode_filename
        }
        
        super().__init__(inputs, cache_path)
        
    
    def get_cached_asset(self) -> pd.DataFrame:
        
        logging.info("Destination choice model already prepared. Reusing the file : " + str(self.cache_path))
        asset = pd.read_parquet(self.cache_path["destination_choice_model"])

        return asset
    
    
    def create_and_get_asset(self) -> pd.DataFrame:
        
        logging.info("Creating destination choice model...")
        
        transport_zones = self.inputs["transport_zones"]
        
        study_area = transport_zones.study_area.get()
        transport_zones = pd.merge(
            transport_zones.get(),
            study_area[["local_admin_unit_id", "country"]],
            on="local_admin_unit_id"
        )
        
        sources, sinks = self.prepare_sources_and_sinks(transport_zones)
        utilities = self.prepare_utilities(transport_zones, sinks)
        
        flows = self.compute_flows(
            transport_zones,
            sources,
            sinks,
            self.costs,
            utilities
        )
        
        
        choice_model = flows[["from", "to", "flow_volume"]].set_index(["from", "to"])["flow_volume"]
        choice_model = choice_model/choice_model.groupby("from").sum()
        choice_model.name = "prob"
        choice_model = choice_model.reset_index()
        
        flows.to_parquet(self.cache_path["od_flows"])
        choice_model.to_parquet(self.cache_path["destination_choice_model"])
        # utility_by_od_and_mode.to_parquet(self.cache_path["utility_by_od_and_mode"])
        
        return choice_model
    
    
    @abstractmethod
    def prepare_reference_flows(self):
        pass
        
    
    @abstractmethod
    def prepare_sources_and_sinks(self):
        pass
    

    # def compute_flows(
    #         self,
    #         transport_zones,
    #         sources: pd.DataFrame,
    #         sinks: pd.DataFrame,
    #         costs,
    #         utilities
    #     ):
        
    #     parameters = self.inputs["parameters"]
        
    #     flows, _, _ = radiation_model_selection.radiation_model_selection(
    #         sources=sources,
    #         sinks=sinks,
    #         costs=costs,
    #         utilities=utilities,
    #         selection_lambda=parameters.model["lambda"]
    #     )
        
    #     flows = flows.to_frame().reset_index()
        
    #     flows = pd.merge(flows, transport_zones[["transport_zone_id", "local_admin_unit_id"]], left_on="from", right_on="transport_zone_id")
    #     flows = pd.merge(flows, transport_zones[["transport_zone_id", "local_admin_unit_id"]], left_on="to", right_on="transport_zone_id", suffixes=["_from", "_to"])
        
    #     flows = flows[["from", "to", "local_admin_unit_id_from", "local_admin_unit_id_to", "flow_volume"]]
        
    #     return flows
    
    
    def get_comparison(self):
        
        flows = pd.read_parquet(self.cache_path["od_flows"])
        flows = flows.groupby(["local_admin_unit_id_from", "local_admin_unit_id_to"], as_index=False)["flow_volume"].sum()
        
        lau_ids = flows["local_admin_unit_id_from"].unique()
        
        ref_flows = self.reference_flows.get()
        ref_flows = ref_flows[ref_flows["local_admin_unit_id_from"].isin(lau_ids) & ref_flows["local_admin_unit_id_to"].isin(lau_ids)]
        ref_flows = ref_flows.groupby(["local_admin_unit_id_from", "local_admin_unit_id_to"], as_index=False)["ref_flow_volume"].sum()

        od_pairs = pd.concat([
            ref_flows[["local_admin_unit_id_from", "local_admin_unit_id_to"]],
            flows[["local_admin_unit_id_from", "local_admin_unit_id_to"]]
        ]).drop_duplicates()
        
        comparison = pd.merge(
            od_pairs,
            flows,
            on=["local_admin_unit_id_from", "local_admin_unit_id_to"],
            how="left"
        )
        
        comparison = pd.merge(
            comparison,
            ref_flows,
            on=["local_admin_unit_id_from", "local_admin_unit_id_to"],
            how="left"
        )
    
        
        comparison.fillna(0.0, inplace=True)
        
        return comparison
    
    
    def compute_ssi(self, comparison, min_flow_volume):
        
        comparison = comparison[comparison["ref_flow_volume"] > min_flow_volume]
        
        num = 2*np.minimum(comparison["ref_flow_volume"], comparison["flow_volume"])
        den = comparison["ref_flow_volume"] + comparison["flow_volume"]
        ssi = np.sum(num/den)/num.shape[0]
        
        return ssi
    
    
    def compute_total_OD_distance_error(self, comparison, travel_costs, min_flow_volume):
        
        comparison = comparison[comparison["ref_flow_volume"] > min_flow_volume]
        
        travel_costs = travel_costs[travel_costs["mode"] == "car"]
        
        comparison = pd.merge(comparison, travel_costs, on=["from", "to"])
        
        comparison["mod_distance"] = comparison["flow_volume"]*comparison["distance"]
        comparison["ref_distance"] = comparison["ref_flow_volume"]*comparison["distance"]
        
        error = comparison["mod_distance"].sum()/comparison["ref_distance"].sum() - 1.0
        
        return error
    
    
    def plot_model_fit(self, comparison):
        
        comparison = comparison.copy()
        comparison["log_ref_flow_volume"] = np.log10(comparison["ref_flow_volume"])
        comparison["log_flow_volume"] = np.log10(comparison["flow_volume"])
        
        sns.set_theme()
        sns.scatterplot(data=comparison, x="log_ref_flow_volume", y="log_flow_volume", size=5, linewidth=0, alpha=0.5)
        
        
